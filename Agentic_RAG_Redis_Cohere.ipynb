{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcaw07/ArXivChatGuru/blob/main/Agentic_RAG_Redis_Cohere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43497beb-817d-4366-9156-f4d7f0d44942",
      "metadata": {
        "id": "43497beb-817d-4366-9156-f4d7f0d44942"
      },
      "source": [
        "# Customer Support RAG Agent\n",
        "*powered by Redis*\n",
        "\n",
        "In this guide, you build an **agent** to perform **RAG** and answer questions related to a car manual PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77ac7184",
      "metadata": {
        "id": "77ac7184"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4eff88ab",
      "metadata": {
        "id": "4eff88ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a458dd-3267-4e8d-c256-303ba1028cf8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.29-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse\n",
            "  Downloading llama_parse-0.4.1-py3-none-any.whl (7.3 kB)\n",
            "Collecting llama-hub\n",
            "  Downloading llama_hub-0.0.79.post1-py3-none-any.whl (103.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.11-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.29 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.29-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.15-py3-none-any.whl (10 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.19-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting html2text (from llama-hub)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama-hub) (5.9.5)\n",
            "Collecting pyaml<24.0.0,>=23.9.7 (from llama-hub)\n",
            "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
            "Collecting retrying (from llama-hub)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n",
            "  Downloading openai-1.19.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (3.9.3)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading llamaindex_py_client-0.1.18-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (4.11.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.29->llama-index) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->llama-hub) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.29->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.29->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.29->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.29->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.29->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.29->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.29->llama-index) (2.6.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.29->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.29->llama-index) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.29->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.29->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.29->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.29->llama-index) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.29->llama-index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.29->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.29->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.29->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.29->llama-index)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.29->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.29->llama-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.29->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.29->llama-index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.29->llama-index) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.29->llama-index) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.29->llama-index) (2.16.3)\n",
            "Building wheels for collected packages: html2text\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=f40cbbbbf0c0579040f077e808ffbc0995ac934f77376ba0b9c1f8b738373882\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\n",
            "Successfully built html2text\n",
            "Installing collected packages: striprtf, dirtyjson, retrying, pypdf, pyaml, mypy-extensions, marshmallow, html2text, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, llama-hub\n",
            "Successfully installed dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 html2text-2024.2.26 httpcore-1.0.5 httpx-0.27.0 llama-hub-0.0.79.post1 llama-index-0.10.29 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.11 llama-index-core-0.10.29 llama-index-embeddings-openai-0.1.7 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.15 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.19 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.1 llamaindex-py-client-0.1.18 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.19.0 pyaml-23.12.0 pypdf-4.2.0 retrying-1.3.4 striprtf-0.0.26 tiktoken-0.6.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-vector-stores-redis\n",
            "  Downloading llama_index_vector_stores_redis-0.2.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-redis) (0.10.29)\n",
            "Collecting redisvl<0.2.0,>=0.1.3 (from llama-index-vector-stores-redis)\n",
            "  Downloading redisvl-0.1.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (0.1.18)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.14.1)\n",
            "Collecting coloredlogs (from redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis>=5.0.0 (from redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis)\n",
            "  Downloading redis-5.0.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.8/251.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis) (2.6.4)\n",
            "Requirement already satisfied: tabulate<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis) (0.9.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.0.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->redisvl<0.2.0,>=0.1.3->llama-index-vector-stores-redis)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-redis) (1.16.0)\n",
            "Installing collected packages: redis, humanfriendly, coloredlogs, redisvl, llama-index-vector-stores-redis\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 llama-index-vector-stores-redis-0.2.0 redis-5.0.3 redisvl-0.1.3\n",
            "Collecting llama-index-storage-docstore-redis\n",
            "  Downloading llama_index_storage_docstore_redis-0.1.2-py3-none-any.whl (2.2 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-storage-docstore-redis) (0.10.29)\n",
            "Collecting llama-index-storage-kvstore-redis<0.2.0,>=0.1.1 (from llama-index-storage-docstore-redis)\n",
            "  Downloading llama_index_storage_kvstore_redis-0.1.3-py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.1.18)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.14.1)\n",
            "Requirement already satisfied: redis<6.0.0,>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-storage-kvstore-redis<0.2.0,>=0.1.1->llama-index-storage-docstore-redis) (5.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.6.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-storage-docstore-redis) (1.16.0)\n",
            "Installing collected packages: llama-index-storage-kvstore-redis, llama-index-storage-docstore-redis\n",
            "Successfully installed llama-index-storage-docstore-redis-0.1.2 llama-index-storage-kvstore-redis-0.1.3\n",
            "Collecting llama-index-storage-chat-store-redis\n",
            "  Downloading llama_index_storage_chat_store_redis-0.1.3-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /usr/local/lib/python3.10/dist-packages (from llama-index-storage-chat-store-redis) (0.10.29)\n",
            "Requirement already satisfied: redis>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-storage-chat-store-redis) (5.0.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.1.18)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.14.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis>=4.1.0->llama-index-storage-chat-store-redis) (4.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.9.4)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.6.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-storage-chat-store-redis) (1.16.0)\n",
            "Installing collected packages: llama-index-storage-chat-store-redis\n",
            "Successfully installed llama-index-storage-chat-store-redis-0.1.3\n",
            "Collecting llama-index-llms-cohere\n",
            "  Downloading llama_index_llms_cohere-0.1.6-py3-none-any.whl (5.0 kB)\n",
            "Collecting cohere<6.0.0,>=5.1.2 (from llama-index-llms-cohere)\n",
            "  Downloading cohere-5.2.6-py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-cohere) (0.10.29)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (0.27.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (2.6.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.16.0,>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (0.15.2)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2023.6.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (0.1.18)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (4.66.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (3.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (0.20.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (1.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (3.13.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere<6.0.0,>=5.1.2->llama-index-llms-cohere) (24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-cohere) (1.16.0)\n",
            "Installing collected packages: types-requests, fastavro, cohere, llama-index-llms-cohere\n",
            "Successfully installed cohere-5.2.6 fastavro-1.9.4 llama-index-llms-cohere-0.1.6 types-requests-2.31.0.20240406\n",
            "Collecting llama-index-embeddings-cohere\n",
            "  Downloading llama_index_embeddings_cohere-0.1.7-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: cohere<6.0.0,>=5.2.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-cohere) (5.2.6)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-cohere) (0.10.29)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (1.9.4)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (0.27.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (2.6.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.16.0,>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (0.15.2)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (2.31.0.20240406)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2023.6.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (0.1.18)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (4.66.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (3.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (0.20.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (1.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (3.13.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere<6.0.0,>=5.2.5->llama-index-embeddings-cohere) (24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-cohere) (1.16.0)\n",
            "Installing collected packages: llama-index-embeddings-cohere\n",
            "Successfully installed llama-index-embeddings-cohere-0.1.7\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "%pip install -U llama-index llama-parse llama-hub\n",
        "%pip install llama-index-vector-stores-redis\n",
        "%pip install llama-index-storage-docstore-redis\n",
        "%pip install llama-index-storage-chat-store-redis\n",
        "%pip install llama-index-llms-cohere\n",
        "%pip install llama-index-embeddings-cohere\n",
        "%pip install llama-index-embeddings-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0e47ac-ec6d-48eb-93a3-0e1fcab22112",
      "metadata": {
        "id": "1f0e47ac-ec6d-48eb-93a3-0e1fcab22112"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be00aba-b6c5-4940-9825-81c5d2cd2f0b",
      "metadata": {
        "id": "9be00aba-b6c5-4940-9825-81c5d2cd2f0b"
      },
      "source": [
        "## Setup and Download Data\n",
        "\n",
        "In this section, we'll set up a simple Redis db, configure the environment, and ingest the PDF document."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Redis"
      ],
      "metadata": {
        "id": "Po4K08Uoa5HJ"
      },
      "id": "Po4K08Uoa5HJ"
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "sudo apt-get update  > /dev/null 2>&1\n",
        "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "redis-stack-server --daemonize yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLy0onoAa7KI",
        "outputId": "e3ba3503-6fd9-4e16-d1b9-fbe963b87e9c"
      },
      "id": "VLy0onoAa7KI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main\n",
            "Starting redis-stack-server, database path /var/lib/redis-stack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REDIS_HOST=\"localhost\"\n",
        "REDIS_PORT=6379\n",
        "REDIS_PASSWORD=\"\""
      ],
      "metadata": {
        "id": "7c2KKPhOh4zM"
      },
      "id": "7c2KKPhOh4zM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Configuration\n",
        "You will need both a LlamaCloud API Key and a Cohere API Key."
      ],
      "metadata": {
        "id": "DTusYzlJa876"
      },
      "id": "DTusYzlJa876"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"YOUR API KEY\"\n",
        "os.environ[\"CO_API_KEY\"] = \"YOUR API KEY\""
      ],
      "metadata": {
        "id": "TjHWvyTtXNiK"
      },
      "id": "TjHWvyTtXNiK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need this for running llama-index code in Jupyter Notebooks\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "b4CGkFIhX86t"
      },
      "id": "b4CGkFIhX86t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download, Parse and Ingest Document\n",
        "First we will download the PDF for this example. We will use a simple bash command to pull the file from a related github project."
      ],
      "metadata": {
        "id": "CEIZjXY9mL6m"
      },
      "id": "CEIZjXY9mL6m"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/'\n",
        "!wget 'https://raw.githubusercontent.com/redis-developer/LLM-Document-Chat/main/docs/2022-chevrolet-colorado-ebrochure.pdf' -O 'data/2022-chevrolet-colorado-ebrochure.pdf'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WsfdF550FYc",
        "outputId": "34e1a1d9-799e-43a3-fa59-2913bb80209c"
      },
      "id": "2WsfdF550FYc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-15 17:35:46--  https://raw.githubusercontent.com/redis-developer/LLM-Document-Chat/main/docs/2022-chevrolet-colorado-ebrochure.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3566101 (3.4M) [application/octet-stream]\n",
            "Saving to: ‘data/2022-chevrolet-colorado-ebrochure.pdf’\n",
            "\n",
            "\r          data/2022   0%[                    ]       0  --.-KB/s               \rdata/2022-chevrolet 100%[===================>]   3.40M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-04-15 17:35:47 (75.6 MB/s) - ‘data/2022-chevrolet-colorado-ebrochure.pdf’ saved [3566101/3566101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LlamaParse on LlamaCloud, parsing the PDF is done with great precision and accuracy."
      ],
      "metadata": {
        "id": "O4B9M1Yiz4v7"
      },
      "id": "O4B9M1Yiz4v7"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "parser = LlamaParse(\n",
        "    result_type=\"markdown\"  # \"markdown\" and \"text\" are available\n",
        ")\n",
        "\n",
        "file_extractor = {\".pdf\": parser}\n",
        "reader = SimpleDirectoryReader(\"./data\", file_extractor=file_extractor)\n",
        "documents = reader.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHhaz-ezW0dy",
        "outputId": "b3346277-d418-4372-cec0-c0c42372131c"
      },
      "id": "iHhaz-ezW0dy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 0fca28d8-a7b3-489b-8711-0be46f35db9e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we build a custom index schema for the `RedisVectorStore` that uses the cohere embedding model and some custom index specifications."
      ],
      "metadata": {
        "id": "Jms33LO5t_6c"
      },
      "id": "Jms33LO5t_6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c3c2a9-c546-410d-9fbd-1a76f8da4ecc",
      "metadata": {
        "id": "c9c3c2a9-c546-410d-9fbd-1a76f8da4ecc"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.cohere import CohereEmbedding\n",
        "from llama_index.core.ingestion import (\n",
        "    DocstoreStrategy,\n",
        "    IngestionPipeline,\n",
        "    IngestionCache,\n",
        ")\n",
        "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
        "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.vector_stores.redis import RedisVectorStore\n",
        "\n",
        "from redisvl.schema import IndexSchema\n",
        "\n",
        "\n",
        "embed_model = CohereEmbedding(input_type=\"search_document\")\n",
        "\n",
        "custom_schema = IndexSchema.from_dict(\n",
        "    {\n",
        "        \"index\": {\n",
        "            \"name\": \"chevy-colorado\",\n",
        "            \"prefix\": \"pdf:chunk\",\n",
        "            \"key_separator\": \":\"\n",
        "          },\n",
        "        # customize fields that are indexed\n",
        "        \"fields\": [\n",
        "            # required fields for llamaindex\n",
        "            {\"type\": \"tag\", \"name\": \"id\"},\n",
        "            {\"type\": \"tag\", \"name\": \"doc_id\"},\n",
        "            {\"type\": \"text\", \"name\": \"text\"},\n",
        "            # custom vector field for cohere embeddings\n",
        "            {\n",
        "                \"type\": \"vector\",\n",
        "                \"name\": \"vector\",\n",
        "                \"attrs\": {\n",
        "                    \"dims\": 1024,\n",
        "                    \"algorithm\": \"hnsw\",\n",
        "                    \"distance_metric\": \"cosine\",\n",
        "                },\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can build an end to end ingestion pipeline as a sequence of transformations backed by a cache, document store, and a sink. **Notice that Redis is used at all stages of the ingest pipeline to process documents at scale, minimizing redundant compute (and thus long-running costs).**"
      ],
      "metadata": {
        "id": "j9expyHYuSN3"
      },
      "id": "j9expyHYuSN3"
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index_pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        SentenceSplitter(),\n",
        "        embed_model,\n",
        "    ],\n",
        "    docstore=RedisDocumentStore.from_host_and_port(\n",
        "        REDIS_HOST, REDIS_PORT, namespace=\"doc-store\"\n",
        "    ),\n",
        "    vector_store=RedisVectorStore(\n",
        "        schema=custom_schema,\n",
        "        redis_url=f\"redis://{REDIS_HOST}:{REDIS_PORT}\",\n",
        "    ),\n",
        "    cache=IngestionCache(\n",
        "        cache=RedisCache.from_host_and_port(REDIS_HOST, REDIS_PORT),\n",
        "        collection=\"doc-cache\",\n",
        "    ),\n",
        "    docstore_strategy=DocstoreStrategy.UPSERTS,\n",
        ")"
      ],
      "metadata": {
        "id": "0QLBztgmZXlD"
      },
      "id": "0QLBztgmZXlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index_pipeline.run(documents=documents, show_progress=True)"
      ],
      "metadata": {
        "id": "AtPIqKFram-f"
      },
      "id": "AtPIqKFram-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test pipeline consistency and optimizations\n",
        "Since we are using the document store and cache, we can run the exact same document through, and note that nothing else is ingested because it's already been done. **This helps prevent redundant computation on ETL, improving costs and throughput at scale.**\n"
      ],
      "metadata": {
        "id": "HefsmjnZaqDX"
      },
      "id": "HefsmjnZaqDX"
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index_pipeline.run(documents=documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xr1yVHqas5b",
        "outputId": "043dcd52-d748-44b3-f683-6f4a56a56c8f"
      },
      "id": "9Xr1yVHqas5b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "976cd798-2e8d-474c-922a-51b12c5c6f36",
      "metadata": {
        "id": "976cd798-2e8d-474c-922a-51b12c5c6f36"
      },
      "source": [
        "## Building the Agent\n",
        "\n",
        "In this section we define a ReAct agent that will perform RAG over a PDF document using the Cohere `command-r-plus` language model.\n",
        "\n",
        "We define both a vector index (for semantic search) and summary index (for summarization) for the document. The two query engines are then converted into tools that are passed to the agent.\n",
        "\n",
        "This agent can dynamically choose to perform semantic search or summarization within the document."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Cohere as the base embedding model and LLM\n",
        "from llama_index.llms.cohere import Cohere\n",
        "from llama_index.core import Settings\n",
        "\n",
        "llm = Cohere(model=\"command-r-plus\")\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = CohereEmbedding(input_type=\"search_query\")"
      ],
      "metadata": {
        "id": "dgczKV4mf_QP"
      },
      "id": "dgczKV4mf_QP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up memory for the Agent\n",
        "from llama_index.storage.chat_store.redis import RedisChatStore\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "\n",
        "# build memory\n",
        "chat_store = RedisChatStore(redis_url=f\"redis://{REDIS_HOST}:{REDIS_PORT}\", ttl=300)\n",
        "\n",
        "chat_memory = ChatMemoryBuffer.from_defaults(\n",
        "    token_limit=3000,\n",
        "    chat_store=chat_store,\n",
        "    chat_store_key=\"user_1\"\n",
        ")"
      ],
      "metadata": {
        "id": "U8q6I7hgtbhS"
      },
      "id": "U8q6I7hgtbhS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eacdf3a7-cfe3-4c2b-9037-b28a065ed148",
      "metadata": {
        "id": "eacdf3a7-cfe3-4c2b-9037-b28a065ed148"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "async def build_doc_agent(doc):\n",
        "    # run ingestion\n",
        "    vector_index_pipeline.run(documents=[doc], show_progress=True)\n",
        "\n",
        "    # grab the nodes\n",
        "    node_parser = SentenceSplitter()\n",
        "    nodes = node_parser.get_nodes_from_documents([doc])\n",
        "\n",
        "    # ID will be base + parent\n",
        "    file_name = doc.metadata[\"file_name\"]\n",
        "    file_id = file_name.replace(\"-\", \"_\").strip(\".pdf\")\n",
        "\n",
        "    print(file_id)\n",
        "\n",
        "    file_path = f\"./data/{file_name}\"\n",
        "    summary_out_path = f\"./data/{file_name}_summary.pkl\"\n",
        "    vector_index = VectorStoreIndex.from_vector_store(\n",
        "        vector_index_pipeline.vector_store\n",
        "    )\n",
        "\n",
        "    # build summary index\n",
        "    summary_index = SummaryIndex(nodes)\n",
        "\n",
        "    # define query engines\n",
        "    vector_query_engine = vector_index.as_query_engine()\n",
        "    summary_query_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\"\n",
        "    )\n",
        "\n",
        "    # extract a summary\n",
        "    summary = str(\n",
        "        await summary_query_engine.aquery(\n",
        "            \"Extract a concise 1-2 line summary of this document\"\n",
        "        )\n",
        "    )\n",
        "    pickle.dump(summary, open(summary_out_path, \"wb\"))\n",
        "\n",
        "\n",
        "    # define tools\n",
        "    query_engine_tools = [\n",
        "        QueryEngineTool(\n",
        "            query_engine=vector_query_engine,\n",
        "            metadata=ToolMetadata(\n",
        "                name=f\"vector_tool_{file_id}\",\n",
        "                description=f\"Useful for questions related to specific facts about the chevy colorado\",\n",
        "            ),\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # build ReAct agent\n",
        "    agent = ReActAgent.from_tools(\n",
        "        query_engine_tools,\n",
        "        llm=llm,\n",
        "        verbose=True,\n",
        "        memory=chat_memory,\n",
        "        context=f\"\"\"\\\n",
        "You are a specialized, trustworthy, helpful, and technical customer support agent designed to answer queries about the Chevy Colorado 2022 vehicle.\n",
        "Use the available tools provided when answering a question. Do NOT just blindly make things up about the car unless it is grounded by the retrieved sources.\\\n",
        "\"\"\")\n",
        "\n",
        "    return agent, summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44748b46-dd6b-4d4f-bc70-7022ae96413f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44748b46-dd6b-4d4f-bc70-7022ae96413f",
        "outputId": "e6f39875-84f7-43ed-8e74-2a8c2bdb6b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022_chevrolet_colorado_ebrochure\n",
            "17:37:36 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "17:37:36 llama_index.core.agent.react.formatter WARNING   ReActChatFormatter.from_context is deprecated, please use `from_defaults` instead.\n"
          ]
        }
      ],
      "source": [
        "agent, doc_summary = await build_doc_agent(documents[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BB12CBvJoSJv",
        "outputId": "3d81665b-dc7d-48fa-fcd9-456e3c2cb1a7"
      },
      "id": "BB12CBvJoSJv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The 2022 Chevrolet Colorado is a midsize pickup truck with four models, three engine options, and various special editions, offering comfort, style, and off-road capabilities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Agent"
      ],
      "metadata": {
        "id": "jXpe-_Vutikn"
      },
      "id": "jXpe-_Vutikn"
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is the seating capacity of the vehicle?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buZkf9Q7ogMN",
        "outputId": "f4bbec14-9fc2-487d-e456-547cc9d90cd2"
      },
      "id": "buZkf9Q7ogMN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:38:22 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: vector_tool_2022_chevrolet_colorado_ebrochure\n",
            "Action Input: {'input': 'How many people can fit in the 2022 Chevy Colorado?'}\n",
            "\u001b[0m17:38:22 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n",
            "17:38:22 llama_index.vector_stores.redis.base INFO   Querying index chevy-colorado with filters *\n",
            "17:38:22 llama_index.vector_stores.redis.base INFO   Found 2 results for query with id ['pdf:chunk:114a33c8-392a-4513-8b85-657e096b1280', 'pdf:chunk:eab44d43-9244-4eb0-9bda-5f68322eb866']\n",
            "17:38:23 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mObservation: The 2022 Chevrolet Colorado can seat up to five people.\n",
            "\u001b[0m17:38:24 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: The 2022 Chevrolet Colorado can seat up to five people.\n",
            "\u001b[0mThe 2022 Chevrolet Colorado can seat up to five people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is the towing capacity?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlrRBScWp_Wy",
        "outputId": "579fe41e-9d5d-4661-96c8-75ac204ae267"
      },
      "id": "XlrRBScWp_Wy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:38:39 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: vector_tool_2022_chevrolet_colorado_ebrochure\n",
            "Action Input: {'input': 'towing capacity'}\n",
            "\u001b[0m17:38:39 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n",
            "17:38:39 llama_index.vector_stores.redis.base INFO   Querying index chevy-colorado with filters *\n",
            "17:38:39 llama_index.vector_stores.redis.base INFO   Found 2 results for query with id ['pdf:chunk:114a33c8-392a-4513-8b85-657e096b1280', 'pdf:chunk:62a70373-57d1-43ba-9961-18c3e44bc956']\n",
            "17:38:44 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mObservation: The 2022 Chevrolet Colorado has a maximum towing capacity of 7,700 lbs when equipped with the available Duramax 2.8L Turbo-Diesel engine. This is based on the Crew Cab Short Box LT 2WD model with the available Trailering Package, LT Convenience Package, and Safety Package. \n",
            "\n",
            "The towing capacity can vary depending on the specific model, cab style, engine, and other factors. For example, the ZR2 model with the Duramax 2.8L I-4 engine has a maximum towing capacity of 5,000 lbs. \n",
            "\n",
            "It's important to carefully review the vehicle's specifications and the Owner's Manual before purchasing or using the vehicle for trailering, as the actual capacity may vary.\n",
            "\u001b[0m17:38:49 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: The towing capacity of the 2022 Chevrolet Colorado varies depending on the specific model and its features. When equipped with the available Duramax 2.8L Turbo-Diesel engine, the Colorado can tow up to an impressive 7,700 lbs. This is based on the Crew Cab Short Box LT 2WD model with specific packages. \n",
            "\n",
            "However, other factors like the cab style and engine type can influence the towing capacity. For example, the ZR2 model with the same Duramax 2.8L engine has a maximum towing capacity of 5,000 lbs. \n",
            "\n",
            "It's important to carefully review the specifications and Owner's Manual before utilizing the vehicle's towing capabilities, as the actual capacity may vary.\n",
            "\u001b[0mThe towing capacity of the 2022 Chevrolet Colorado varies depending on the specific model and its features. When equipped with the available Duramax 2.8L Turbo-Diesel engine, the Colorado can tow up to an impressive 7,700 lbs. This is based on the Crew Cab Short Box LT 2WD model with specific packages. \n",
            "\n",
            "However, other factors like the cab style and engine type can influence the towing capacity. For example, the ZR2 model with the same Duramax 2.8L engine has a maximum towing capacity of 5,000 lbs. \n",
            "\n",
            "It's important to carefully review the specifications and Owner's Manual before utilizing the vehicle's towing capabilities, as the actual capacity may vary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Is there a trailer hitch on the back of the truck?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9WBrCZbqJL9",
        "outputId": "ce78bb69-b07d-4430-a8ca-3eba9c0d3f25"
      },
      "id": "z9WBrCZbqJL9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:38:59 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Yes, the 2022 Chevrolet Colorado is available with a trailer hitch receiver, which is located at the back of the truck. This allows for easy towing and hauling of trailers or other equipment.\n",
            "\u001b[0mYes, the 2022 Chevrolet Colorado is available with a trailer hitch receiver, which is located at the back of the truck. This allows for easy towing and hauling of trailers or other equipment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Tell me about the pros and cons of this truck.\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP4vNtnBqUIZ",
        "outputId": "0fa51f8c-364b-4df5-c567-867e099685d0"
      },
      "id": "dP4vNtnBqUIZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:39:14 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
            "Action: vector_tool_2022_chevrolet_colorado_ebrochure\n",
            "Action Input: {'input': 'Pros and cons of the 2022 Chevrolet Colorado.'}\n",
            "\u001b[0m17:39:15 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n",
            "17:39:15 llama_index.vector_stores.redis.base INFO   Querying index chevy-colorado with filters *\n",
            "17:39:15 llama_index.vector_stores.redis.base INFO   Found 2 results for query with id ['pdf:chunk:114a33c8-392a-4513-8b85-657e096b1280', 'pdf:chunk:eab44d43-9244-4eb0-9bda-5f68322eb866']\n",
            "17:39:20 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mObservation: Pros: \n",
            "- A wide range of models, cab styles, and engines to choose from, ensuring customers can find a configuration that suits their needs.\n",
            "- Impressive fuel efficiency, with a diesel engine option offering up to 30 MPG on the highway.\n",
            "- Strong towing capacity, capable of handling up to 7,700 lbs. with the available diesel engine.\n",
            "- Off-road capabilities, particularly with the ZR2 model, which can tackle rugged terrain.\n",
            "- Comfortable and well-equipped interior, featuring modern technology and convenience features.\n",
            "- Apple CarPlay and Android Auto compatibility.\n",
            "\n",
            "Cons: \n",
            "- Due to supply chain issues, some features may have limited availability or may no longer be offered.\n",
            "- The base model may lack certain standard features that are available on competing trucks.\n",
            "- The Extended Cab's rear seats may feel cramped for taller passengers.\n",
            "- The V6 engine is required for certain features, which may increase the overall cost.\n",
            "\u001b[0m17:39:30 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Here are some of the pros and cons of the 2022 Chevrolet Colorado: \n",
            "\n",
            "**Pros:**\n",
            "- Versatility: Chevrolet Colorado offers a wide range of models, cab styles, and engine options to suit different customer needs and preferences. \n",
            "- Fuel Efficiency: With a diesel engine option, the Colorado achieves impressive fuel economy, delivering up to 30 MPG on the highway. \n",
            "- Towing Capacity: When equipped with the available Duramax 2.8L Turbo-Diesel engine, the Colorado can tow up to 7,700 lbs., making it a capable partner for hauling tasks. \n",
            "- Off-Road Capabilities: The ZR2 model is designed to handle rugged terrain, offering an exciting off-road experience. \n",
            "- Comfort and Technology: The interior is comfortable and well-equipped, featuring modern conveniences and technology, including Apple CarPlay and Android Auto compatibility. \n",
            "\n",
            "**Cons:**\n",
            "- Feature Availability: Due to supply chain issues, certain desired features may have limited availability or may not be offered. \n",
            "- Base Model Features: The base model may lack some standard features that are available on competing trucks, requiring upgrades to access certain functionalities. \n",
            "- Rear Seat Space: The Extended Cab model offers cramped rear seats, which may not be comfortable for taller passengers. \n",
            "- Cost Considerations: To access certain features, such as the V6 engine, upgrades may be necessary, increasing the overall cost of the vehicle. \n",
            "\n",
            "These points provide a balanced perspective on the strengths and weaknesses of the 2022 Chevrolet Colorado, allowing potential buyers to make an informed decision based on their specific needs and priorities.\n",
            "\u001b[0mHere are some of the pros and cons of the 2022 Chevrolet Colorado: \n",
            "\n",
            "**Pros:**\n",
            "- Versatility: Chevrolet Colorado offers a wide range of models, cab styles, and engine options to suit different customer needs and preferences. \n",
            "- Fuel Efficiency: With a diesel engine option, the Colorado achieves impressive fuel economy, delivering up to 30 MPG on the highway. \n",
            "- Towing Capacity: When equipped with the available Duramax 2.8L Turbo-Diesel engine, the Colorado can tow up to 7,700 lbs., making it a capable partner for hauling tasks. \n",
            "- Off-Road Capabilities: The ZR2 model is designed to handle rugged terrain, offering an exciting off-road experience. \n",
            "- Comfort and Technology: The interior is comfortable and well-equipped, featuring modern conveniences and technology, including Apple CarPlay and Android Auto compatibility. \n",
            "\n",
            "**Cons:**\n",
            "- Feature Availability: Due to supply chain issues, certain desired features may have limited availability or may not be offered. \n",
            "- Base Model Features: The base model may lack some standard features that are available on competing trucks, requiring upgrades to access certain functionalities. \n",
            "- Rear Seat Space: The Extended Cab model offers cramped rear seats, which may not be comfortable for taller passengers. \n",
            "- Cost Considerations: To access certain features, such as the V6 engine, upgrades may be necessary, increasing the overall cost of the vehicle. \n",
            "\n",
            "These points provide a balanced perspective on the strengths and weaknesses of the 2022 Chevrolet Colorado, allowing potential buyers to make an informed decision based on their specific needs and priorities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.memory.chat_store.get_messages(\"user_1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kngLFj1m2x2y",
        "outputId": "75172f8f-436c-405c-fdc5-6ae02444ed81"
      },
      "id": "kngLFj1m2x2y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the seating capacity of the vehicle?', additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The 2022 Chevrolet Colorado can seat up to five people.', additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the towing capacity?', additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"The towing capacity of the 2022 Chevrolet Colorado varies depending on the specific model and its features. When equipped with the available Duramax 2.8L Turbo-Diesel engine, the Colorado can tow up to an impressive 7,700 lbs. This is based on the Crew Cab Short Box LT 2WD model with specific packages. \\n\\nHowever, other factors like the cab style and engine type can influence the towing capacity. For example, the ZR2 model with the same Duramax 2.8L engine has a maximum towing capacity of 5,000 lbs. \\n\\nIt's important to carefully review the specifications and Owner's Manual before utilizing the vehicle's towing capabilities, as the actual capacity may vary.\", additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, content='Is there a trailer hitch on the back of the truck?', additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Yes, the 2022 Chevrolet Colorado is available with a trailer hitch receiver, which is located at the back of the truck. This allows for easy towing and hauling of trailers or other equipment.', additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, content='Tell me about the pros and cons of this truck.', additional_kwargs={}),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Here are some of the pros and cons of the 2022 Chevrolet Colorado: \\n\\n**Pros:**\\n- Versatility: Chevrolet Colorado offers a wide range of models, cab styles, and engine options to suit different customer needs and preferences. \\n- Fuel Efficiency: With a diesel engine option, the Colorado achieves impressive fuel economy, delivering up to 30 MPG on the highway. \\n- Towing Capacity: When equipped with the available Duramax 2.8L Turbo-Diesel engine, the Colorado can tow up to 7,700 lbs., making it a capable partner for hauling tasks. \\n- Off-Road Capabilities: The ZR2 model is designed to handle rugged terrain, offering an exciting off-road experience. \\n- Comfort and Technology: The interior is comfortable and well-equipped, featuring modern conveniences and technology, including Apple CarPlay and Android Auto compatibility. \\n\\n**Cons:**\\n- Feature Availability: Due to supply chain issues, certain desired features may have limited availability or may not be offered. \\n- Base Model Features: The base model may lack some standard features that are available on competing trucks, requiring upgrades to access certain functionalities. \\n- Rear Seat Space: The Extended Cab model offers cramped rear seats, which may not be comfortable for taller passengers. \\n- Cost Considerations: To access certain features, such as the V6 engine, upgrades may be necessary, increasing the overall cost of the vehicle. \\n\\nThese points provide a balanced perspective on the strengths and weaknesses of the 2022 Chevrolet Colorado, allowing potential buyers to make an informed decision based on their specific needs and priorities.', additional_kwargs={})]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Incorportating Semantic Caching\n",
        "We can also take advantage of frequently asked questions (live or prefetched) in order to improve response times."
      ],
      "metadata": {
        "id": "9qieviUEtpmn"
      },
      "id": "9qieviUEtpmn"
    },
    {
      "cell_type": "code",
      "source": [
        "from redisvl.extensions.llmcache import SemanticCache\n",
        "from redisvl.utils.vectorize import HFTextVectorizer\n",
        "\n",
        "emb = HFTextVectorizer(model=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "cache = SemanticCache(\n",
        "    name=\"chevy_cache\",\n",
        "    prefix=\"cache\",\n",
        "    distance_threshold=0.1,\n",
        "    ttl=60,\n",
        "    vectorizer=emb\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "fc1ec9b0a4fd41ba9231dc4a32b9665a",
            "32e83a91cd8340cbad2375e5e250938e",
            "1b23104be5c344ca8833a2fde218987d",
            "ec0d838cb9d04b44afd8ebda3f00f3ca",
            "e6e6a2a8334d41cc9d680ffa9adaf566",
            "d19fd57778554d308fef219764d1bf1e",
            "fa58cc8cacf3456ebebeb938fdcbda49",
            "86e1e895513c4fdd95475c7d8cf24c60",
            "650db3141c58427e914019d039aae51e",
            "cdcd6f9f38df4b22b8da4d98d49413e7",
            "de0ad23ee2684653b308fc473457d1a9"
          ]
        },
        "id": "344-RjcW2GXL",
        "outputId": "affa554e-23aa-4d46-f16f-9bbdb26db96e"
      },
      "id": "344-RjcW2GXL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:57:25 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
            "17:57:26 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc1ec9b0a4fd41ba9231dc4a32b9665a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_agent(prompt: str) -> str:\n",
        "    if cached_result := cache.check(prompt=prompt):\n",
        "        response = cached_result[0]['response']\n",
        "        return response\n",
        "    response = agent.chat(prompt)\n",
        "    cache.store(prompt=prompt, response=response.response)\n",
        "    return response.response"
      ],
      "metadata": {
        "id": "QXGdA5ga2pod"
      },
      "id": "QXGdA5ga2pod",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can perform a simple test with our agent and semantic caching enabled."
      ],
      "metadata": {
        "id": "OlNK1VFc3m8q"
      },
      "id": "OlNK1VFc3m8q"
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_agent(\"How many doors does the truck have?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328,
          "referenced_widgets": [
            "2d85ba50975e42008200684d2ede2a3f",
            "e1c428e6ac6e421f86798ad9a5c104ed",
            "a783974d3b2e41668946d77652bd594a",
            "bfb79e564fc74553b38887dfb186bdd2",
            "ecb8cc015bbc43f483cca70b02f5b9fe",
            "7b24f11e2fee4fa9923f3ab6d9f1be80",
            "3707fee24d47408bb2eb8ad763840dad",
            "584a4f3f8f4845aeb0de79a96d372c6a",
            "93dc31f6d8394b799cc6eb41a333190f",
            "9547ebe171ec4af0b695f1b1ef7c1186",
            "4c1344bd30544a42bc117f880d71b485",
            "aa31b58b52fb4424b3c231648c59203a",
            "d11313b2067344c59e0ce8b14a2f4a47",
            "ce1e5fb693f34837afa139525238ca73",
            "7991d54180b84b728cdffe04c12b9238",
            "c54426bfc446413c8c216a32bd933191",
            "1a6e12250a22439e9f626ac9915e290a",
            "e7d0e4799ed244baa46c5e5f7f98701c",
            "cac5882bb79f4f2a8a0c79d7756f01a3",
            "0f8173bc6c014ff4bb335a21a9d22a89",
            "77d78fb58dab4a81a31b4be8a666eae4",
            "e2ea6ea7d82d4bd891782fc1978cfcf5"
          ]
        },
        "id": "kVVJlhfC3mPW",
        "outputId": "6be563ea-90fc-4083-a44d-ce8da978d7b7"
      },
      "id": "kVVJlhfC3mPW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d85ba50975e42008200684d2ede2a3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:57:34 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: vector_tool_2022_chevrolet_colorado_ebrochure\n",
            "Action Input: {'input': 'How many doors does the truck have?'}\n",
            "\u001b[0m17:57:34 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n",
            "17:57:34 llama_index.vector_stores.redis.base INFO   Querying index chevy-colorado with filters *\n",
            "17:57:34 llama_index.vector_stores.redis.base INFO   Found 2 results for query with id ['pdf:chunk:8224d4aa-fb23-4689-9a1d-f79d192ca2e5', 'pdf:chunk:114a33c8-392a-4513-8b85-657e096b1280']\n",
            "17:57:35 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;34mObservation: The truck has four doors.\n",
            "\u001b[0m17:57:36 httpx INFO   HTTP Request: POST https://api.cohere.ai/v1/chat \"HTTP/1.1 200 OK\"\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: The Chevy Colorado has four doors.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa31b58b52fb4424b3c231648c59203a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Chevy Colorado has four doors.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_agent(\"How many doors does the chevy have?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "59691043396740359149f0c8d02431ab",
            "5f96fd4496fc440d811b9434502f2d39",
            "dab94323bec24f1c86dd154f317dcac4",
            "34cb0ea9fd3347818949882aececa3ce",
            "f25097c013324ce4b8b53eb073f5ec79",
            "d9435b41960a4a65a551b843bea19fcf",
            "a25c533e66d848a3bb647a94fadf9055",
            "15e3ee7041744d76a4247341645ffbdd",
            "fca43e0aa06f412399c4f702993db0a6",
            "14e212bbe98045d48b85ab1880f4e297",
            "6aa42aeacb4d48ecaebbb20b6dbef650"
          ]
        },
        "id": "c37ICAFr5bQs",
        "outputId": "9177c7f7-c5f2-4e6e-e447-5f364855d9fa"
      },
      "id": "c37ICAFr5bQs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59691043396740359149f0c8d02431ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Chevy Colorado has four doors.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extending Semantic Caching\n",
        "\n",
        "\n",
        "There are a few options for working with semantic caching in a true production setting:\n",
        "1.   Extract FAQs from your Knowledge Base (pdfs...). Use an LLM to help! Or use human experts. Prefetch into the cache.\n",
        "2. Carefully, extract FAQs from conversation history. Prefetch in batches into the cache each day or week.\n",
        "3. Cache in realtime, which is tricky and requires some tuning. This should typically be done only at the USER level, not across the entire domain or application.\n",
        "\n",
        "**Stay tuned for more dedicated guides on semantic caching for RAG Agents and Redis.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wvfTze4m3mhW"
      },
      "id": "wvfTze4m3mhW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_index_v2",
      "language": "python",
      "name": "llama_index_v2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc1ec9b0a4fd41ba9231dc4a32b9665a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32e83a91cd8340cbad2375e5e250938e",
              "IPY_MODEL_1b23104be5c344ca8833a2fde218987d",
              "IPY_MODEL_ec0d838cb9d04b44afd8ebda3f00f3ca"
            ],
            "layout": "IPY_MODEL_e6e6a2a8334d41cc9d680ffa9adaf566"
          }
        },
        "32e83a91cd8340cbad2375e5e250938e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d19fd57778554d308fef219764d1bf1e",
            "placeholder": "​",
            "style": "IPY_MODEL_fa58cc8cacf3456ebebeb938fdcbda49",
            "value": "Batches: 100%"
          }
        },
        "1b23104be5c344ca8833a2fde218987d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e1e895513c4fdd95475c7d8cf24c60",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_650db3141c58427e914019d039aae51e",
            "value": 1
          }
        },
        "ec0d838cb9d04b44afd8ebda3f00f3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdcd6f9f38df4b22b8da4d98d49413e7",
            "placeholder": "​",
            "style": "IPY_MODEL_de0ad23ee2684653b308fc473457d1a9",
            "value": " 1/1 [00:00&lt;00:00, 16.19it/s]"
          }
        },
        "e6e6a2a8334d41cc9d680ffa9adaf566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19fd57778554d308fef219764d1bf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa58cc8cacf3456ebebeb938fdcbda49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e1e895513c4fdd95475c7d8cf24c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650db3141c58427e914019d039aae51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdcd6f9f38df4b22b8da4d98d49413e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0ad23ee2684653b308fc473457d1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d85ba50975e42008200684d2ede2a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1c428e6ac6e421f86798ad9a5c104ed",
              "IPY_MODEL_a783974d3b2e41668946d77652bd594a",
              "IPY_MODEL_bfb79e564fc74553b38887dfb186bdd2"
            ],
            "layout": "IPY_MODEL_ecb8cc015bbc43f483cca70b02f5b9fe"
          }
        },
        "e1c428e6ac6e421f86798ad9a5c104ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b24f11e2fee4fa9923f3ab6d9f1be80",
            "placeholder": "​",
            "style": "IPY_MODEL_3707fee24d47408bb2eb8ad763840dad",
            "value": "Batches: 100%"
          }
        },
        "a783974d3b2e41668946d77652bd594a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584a4f3f8f4845aeb0de79a96d372c6a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93dc31f6d8394b799cc6eb41a333190f",
            "value": 1
          }
        },
        "bfb79e564fc74553b38887dfb186bdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9547ebe171ec4af0b695f1b1ef7c1186",
            "placeholder": "​",
            "style": "IPY_MODEL_4c1344bd30544a42bc117f880d71b485",
            "value": " 1/1 [00:00&lt;00:00, 14.67it/s]"
          }
        },
        "ecb8cc015bbc43f483cca70b02f5b9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b24f11e2fee4fa9923f3ab6d9f1be80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3707fee24d47408bb2eb8ad763840dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584a4f3f8f4845aeb0de79a96d372c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93dc31f6d8394b799cc6eb41a333190f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9547ebe171ec4af0b695f1b1ef7c1186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1344bd30544a42bc117f880d71b485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa31b58b52fb4424b3c231648c59203a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d11313b2067344c59e0ce8b14a2f4a47",
              "IPY_MODEL_ce1e5fb693f34837afa139525238ca73",
              "IPY_MODEL_7991d54180b84b728cdffe04c12b9238"
            ],
            "layout": "IPY_MODEL_c54426bfc446413c8c216a32bd933191"
          }
        },
        "d11313b2067344c59e0ce8b14a2f4a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a6e12250a22439e9f626ac9915e290a",
            "placeholder": "​",
            "style": "IPY_MODEL_e7d0e4799ed244baa46c5e5f7f98701c",
            "value": "Batches: 100%"
          }
        },
        "ce1e5fb693f34837afa139525238ca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac5882bb79f4f2a8a0c79d7756f01a3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f8173bc6c014ff4bb335a21a9d22a89",
            "value": 1
          }
        },
        "7991d54180b84b728cdffe04c12b9238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d78fb58dab4a81a31b4be8a666eae4",
            "placeholder": "​",
            "style": "IPY_MODEL_e2ea6ea7d82d4bd891782fc1978cfcf5",
            "value": " 1/1 [00:00&lt;00:00, 15.01it/s]"
          }
        },
        "c54426bfc446413c8c216a32bd933191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6e12250a22439e9f626ac9915e290a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d0e4799ed244baa46c5e5f7f98701c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac5882bb79f4f2a8a0c79d7756f01a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8173bc6c014ff4bb335a21a9d22a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77d78fb58dab4a81a31b4be8a666eae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ea6ea7d82d4bd891782fc1978cfcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59691043396740359149f0c8d02431ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f96fd4496fc440d811b9434502f2d39",
              "IPY_MODEL_dab94323bec24f1c86dd154f317dcac4",
              "IPY_MODEL_34cb0ea9fd3347818949882aececa3ce"
            ],
            "layout": "IPY_MODEL_f25097c013324ce4b8b53eb073f5ec79"
          }
        },
        "5f96fd4496fc440d811b9434502f2d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9435b41960a4a65a551b843bea19fcf",
            "placeholder": "​",
            "style": "IPY_MODEL_a25c533e66d848a3bb647a94fadf9055",
            "value": "Batches: 100%"
          }
        },
        "dab94323bec24f1c86dd154f317dcac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e3ee7041744d76a4247341645ffbdd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fca43e0aa06f412399c4f702993db0a6",
            "value": 1
          }
        },
        "34cb0ea9fd3347818949882aececa3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e212bbe98045d48b85ab1880f4e297",
            "placeholder": "​",
            "style": "IPY_MODEL_6aa42aeacb4d48ecaebbb20b6dbef650",
            "value": " 1/1 [00:00&lt;00:00,  8.47it/s]"
          }
        },
        "f25097c013324ce4b8b53eb073f5ec79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9435b41960a4a65a551b843bea19fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25c533e66d848a3bb647a94fadf9055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15e3ee7041744d76a4247341645ffbdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca43e0aa06f412399c4f702993db0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14e212bbe98045d48b85ab1880f4e297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa42aeacb4d48ecaebbb20b6dbef650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}